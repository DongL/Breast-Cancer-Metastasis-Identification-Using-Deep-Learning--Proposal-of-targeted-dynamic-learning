[Report](https://github.com/DongL/Breast-Cancer-Metastasis-Identification-Using-Deep-Learning--Proposal-of-targeted-dynamic-learning/blob/master/Breast%20Cancer%20Metastases%20Indentification%20using%20Deep%20Learning.pdf) 

The html files can be previewed using [Github Html Preview](https://htmlpreview.github.io)

---

# Breast Cancer Metastases Identification using Deep Learning

## ABSTRACT

Breast cancer patient if diagnosed in early stage has high 5-year survival rate. However, the tumor grading and cancer staging procedure which involves manually determined by pathologies under microscopes are time-consuming and prone to mistakes. This project proposed a two-staged identification model using deep learning to identify isolated tumor region in whole slide images of H&E stained lymph nodes slides and a targeted dynamic algorithm to strength as well as maintain model’s accuracy.


## I. BACKGROUND
Breast cancer is the second most common cause of death from cancer in women in the United States. However, if the patient is diagnosed in early stage, the survival rate is very high. According to National Cancer Institute, the 5-year relative survival rate for localized breast cancer is 99%, whereas when cancer cells spreads to the nearby lymph nodes, the 5-year survival rate is 85%. If the cancer cells enter the distant parts of the body, the survival rate is only 27%. The detection and classification of cancer cells in nearly lymph nodes has significant meaning for breast cancer prognosis.
Surgically removed lymph nodes must go through a complex and long preparation and staining procedure in order to be examined under the microscope by pathologists. The size of the cancer cells and the number of cancer cells (if existed) are the determinants for what stage the cancer is and how far the cancer has progressed in the body. The most common and useful cancer staging system for invasive breast cancer is created by The American Joint Committee on Cancer. The system is called TNM staging system. T refers to tumor size, N refers to nearby lymph nodes status, M refers to metastasis in the distant lymph nodes.
Any work involved manually inspecting samples through microscope is time-consuming and prone to mistakes [1], as it is very difficult to detect small metastases. Spurred by recent development in deep learning and whole-slide scanner technology, Camelyon 16 [2] public challenge was organized in year 2016 by Radboud University Medical Center (Nijmegen, the Netherlands) and the University Medical Center Utrecht (Utrecht, the Netherlands) to evaluate new and existing algorithms for automated detection of metastases in stained whole-slide images of lymph node sections, and subsequently Camelyon 17 [3] was created in year 2017 by Diagnostic Image Analysis Group (DIAG) and Department of Pathology of the Radboud University Medical Center in Nijmegen, The Netherlands to further classify metastasis into three categories (Table 1). The best performing algorithm in Camelyon 16 performed equally well as a pathologist under no time constrain in terms of detection accuracy. The top-5 team in Camelyon 16 achieved AUC 0.9935 to 0.9234 for whole-slide- image classification and a composite score of 0.8074 to 0.6933 for tumor localization.

...

## VI. CONCLUDING REMARKS
In this project, we developed an innovative dynamic training algorithm, called targeted dynamic training to expose model to new error-prone data in order to gradually improve its accuracy among mis-identified data. At each exposure, positively identified data also being fed into the model in order to maintain model’s accuracy with positive data. We also developed a 2-stage identification model employed smallest patch size among published researches. Due to time and resource constrains, methodology in this project is limited as proof of concept.
It has been a discovery journey for us, technology wise and reality wise. We choose this project because it has a real-life application. It has potential to save people’s lives by expanding the limitation and horizon of what humans can do in terms of efficiency and accuracy. It is the manifestation of what’s represented in the saying of Technology changes life. However, this project also showcased how heavily AI application like this relies on hardware. Whole slide scanners, high performance computer clusters with GPUs, rewiring infrastructure required intensive capital investment. There are probably only a handful of pathology labs have the financial means to adopt this application. Giant IT companies, Google and Amazon both provides remotely accessible GPUs as a solution, but not for project like this involving deep learning on large images. From our experience Google Cloud is unstable and failed to run any of the algorithm in our identification model.
History repeats itself. There were times in early days of personal computers history that people had to buy a terminal and blocks of computer time in a remote system. We imagine that there will be a technology breakthrough which will lead to make AI more affordable and accessible to the general public. Only until that time, the power of AI will truly be harvested by human to make our lives better and change our lives in an unforeseeable manner.
